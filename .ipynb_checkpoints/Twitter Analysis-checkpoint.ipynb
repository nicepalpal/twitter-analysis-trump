{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General:\n",
    "import tweepy           # To consume Twitter's API\n",
    "import pandas as pd     # To handle data\n",
    "import numpy as np      # For number computing\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General:\n",
    "import tweepy           # To consume Twitter's API\n",
    "import pandas as pd     # To handle data\n",
    "import numpy as np      # For number computing\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "#Import Twitter Access Keys\n",
    "\n",
    "from credentials import * #Allow us to use the keys as variables\n",
    "\n",
    "#API setup\n",
    "\n",
    "def twitter_setup():\n",
    "\n",
    "    \"\"\"\n",
    "    Utility function to setup Twitter's API \n",
    "    with our access keys provided.\n",
    "    \"\"\"\n",
    "    #Authentication and access using keys, the below is basically creating an OAuthInstance that has our information that wil automatically log us in.\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "    \n",
    "    #Return API with authentication\n",
    "    api = tweepy.API(auth)\n",
    "    return api\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create an extractor object:\n",
    "#(I think this basically means that we use \n",
    "#the twitter_setup to log in and extract information)\n",
    "extractor = twitter_setup()\n",
    "    \n",
    "#Create a tweet list:\n",
    "#User_timeline returns the most 20 recent statuses from the user specified\n",
    "#and has multiple parameters\n",
    "tweets = extractor.user_timeline(screen_name=\"realDonaldTrump\", count=200)\n",
    "#Using format as below allows you to put numbers in a character string\n",
    "print(\"Number of tweets extracted: {}.\\n\".format(len(tweets)))\n",
    "    \n",
    "#We print the most recent 5 tweets:\n",
    "#\\n is a new line\n",
    "print(\"5 recent tweets:\\n\")\n",
    "#prints in the range up to 5 for tweets\n",
    "for tweet in tweets[:5]:\n",
    "    print(tweet.text)\n",
    "    print()\n",
    "\n",
    "#We create a pandas dataframe as follows\n",
    "\n",
    "data = pd.DataFrame(data=[tweet.text for tweet in tweets], columns = ['Tweets'])\n",
    "\n",
    "#We display the first 10 elements of the dataframe:\n",
    "display(data.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Internal methods and metadata contained in a Tweet object in tweepy\n",
    "print(dir(tweets[0]))\n",
    "\n",
    "print(tweets[0].id)\n",
    "print(tweets[0].created_at)\n",
    "print(tweets[0].source)\n",
    "print(tweets[0].favorite_count)\n",
    "print(tweets[0].retweet_count)\n",
    "print(tweets[0].geo)\n",
    "print(tweets[0].coordinates)\n",
    "print(tweets[0].entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add metadata to Dataframe\n",
    "\n",
    "#list comprehension : new_list = expression(i) for variable in old_List\n",
    "data['len'] = np.array([len(tweet.text) for tweet in tweets])\n",
    "data['ID'] = np.array([tweet.id for tweet in tweets])\n",
    "data['Date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "data['Source'] = np.array([tweet.source for tweet in tweets])\n",
    "data['Likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "data['RTs'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "\n",
    "#Display of first 10 elements from data frame\n",
    "display(data.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We extract the mean of lengths\n",
    "\n",
    "mean = np.mean(data['len'])\n",
    "\n",
    "#Below is formatting a list when inputting variables\n",
    "print(\"The length's average in tweets: {}\".format(mean))\n",
    "\n",
    "#We extract the tweet with more FAVs and more RTs, this uses the meta data we assigned above:\n",
    "fav_max = np.max(data['Likes'])\n",
    "rt_max = np.max(data['RTs'])\n",
    "\n",
    "#Below is finding the tweet that has the most likes by seeing if it has the same amount of like sas our fav_max variable\n",
    "#Same for retweets\n",
    "fav = data[data.Likes == fav_max].index[0]\n",
    "rt = data[data.RTs == rt_max].index[0]\n",
    "\n",
    "#Max FAVs:\n",
    "\n",
    "print(\"The tweet with more likes is: \\n{}\".format(data['Tweets'][fav]))\n",
    "print(\"Number of likes: {}\".format(fav_max))\n",
    "print(\"{} characters.\\n\".format(data['len'][fav]))\n",
    "\n",
    "#Max RTs:\n",
    "print(\"The tweet with more retweets is: \\n{}\".format(data['Tweets'][rt]))\n",
    "print(\"Number of retweets: {}\".format(rt_max))\n",
    "print(\"{} characters.\\n\".format(data['len'][rt]))\n",
    "\n",
    "\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas Plotting\n",
    "#Create a time series for data:\n",
    "\n",
    "tlen = pd.Series(data=data['len'].values, index=data['Date'])\n",
    "tfav = pd.Series(data=data['Likes'].values, index=data['Date'])\n",
    "tret = pd.Series(data=data['RTs'].values, index=data['Date'])\n",
    "\n",
    "#Lengths along time:\n",
    "\n",
    "tlen.plot(figsize=(16,4), label = \"Tweet Length\", color='r', legend = True);\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Likes vs Retweets Visualization\n",
    "tfav.plot(figsize=(16, 4), label= \"Likes\", legend=True)\n",
    "tret.plot(figsize=(16, 4), label=\"Retweets\", legend=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Piechart of sources\n",
    "\n",
    "#We obtain all possible sources\n",
    "\n",
    "sources = []\n",
    "for source in data['Source']:\n",
    "    if source not in sources:\n",
    "        sources.append(source)\n",
    "\n",
    "#Print sources list\n",
    "print(\"Creation of content sources:\")\n",
    "for source in sources:\n",
    "    print(\"*{}\".format(source))\n",
    "\n",
    "#Create a numpy vector maped to labels\n",
    "\n",
    "percent = np.zeros(len(sources))\n",
    "\n",
    "for source in data['Source']:\n",
    "    for index in range(len(sources)):\n",
    "        if source == sources[index]:\n",
    "            percent[index] += 1\n",
    "            pass\n",
    "percent /= 100\n",
    "\n",
    "#Pie chart:\n",
    "pie_chart = pd.Series(percent, index=sources, name='Sources')\n",
    "pie_chart.plot.pie(fontsize=11, autopct='%.2f', figsize=(6,6));\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis \n",
    "\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean th etext in a tweet by removing\n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    \n",
    "    return ' '.join(re.sub(\"([@A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def analyze_sentiment(tweet):\n",
    "    analysis = TextBlog(clean_tweet(tweet))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "#We create a column with the result of the analysis:\n",
    "\n",
    "data['SA'] = np.array([analyze_sentiment(tweet) for tweet in data ['Tweets']])\n",
    "\n",
    "#We display the updated dataframe with the new column\n",
    "\n",
    "display(data.head(10))\n",
    "\n",
    "pos_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data ['SA'][index] > 0]\n",
    "neu_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data ['SA'][index] == 0]\n",
    "neg_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data ['SA'][index] < 0]\n",
    "\n",
    "\n",
    "print(\"Percentage of positive tweets: {}%\".format(len(pos_tweets)*100/len(data['Tweets'])))\n",
    "print(\"Percentage of neutral tweets: {}%\".format(len(neu_tweets)*100/len(data['Tweets'])))\n",
    "print(\"Percentage de negative tweets: {}%\".format(len(neg_tweets)*100/len(data['Tweets'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
